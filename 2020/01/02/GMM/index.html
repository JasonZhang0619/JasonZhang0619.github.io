<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Jiaxin Zhang" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="Gaussian Mixture Model is one of clustering model. Clustering is an unsupervised learning problem where we intend to find clusters of points in our dataset that share some common characteristics.   No">
<meta name="keywords" content="Python, R, SQL, SPSS, Machine Learning, NLP, Statistics, Data Analysis">
<meta property="og:type" content="article">
<meta property="og:title" content="Gaussian Mixture Model (GMM) and Expectation–Maximization (EM)">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;01&#x2F;02&#x2F;GMM&#x2F;index.html">
<meta property="og:site_name" content="Jiaxin Zhang">
<meta property="og:description" content="Gaussian Mixture Model is one of clustering model. Clustering is an unsupervised learning problem where we intend to find clusters of points in our dataset that share some common characteristics.   No">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2020-01-04T08:12:31.508Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/01/02/GMM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Gaussian Mixture Model (GMM) and Expectation–Maximization (EM) | Jiaxin Zhang</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiaxin Zhang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">MSc in Statistical Machine Learning @ UofA</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/JasonZhang0619" class="github-corner" title="GitHub" aria-label="GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/02/GMM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Jiaxin Zhang">
      <meta itemprop="description" content="4+ years experience in programming. Familiar with python, SQL server, R, and Git. Highly motivated and humble to learn new things and learn fast with practice. Enjoy teamwork with strong sense of responsibility and communication skills, but also able to work individually with high efficiency, strong self-discipline and problem solving ability.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaxin Zhang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Gaussian Mixture Model (GMM) and Expectation–Maximization (EM)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-02 21:44:47" itemprop="dateCreated datePublished" datetime="2020-01-02T21:44:47-07:00">2020-01-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-04 01:12:31" itemprop="dateModified" datetime="2020-01-04T01:12:31-07:00">2020-01-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Gaussian Mixture Model is one of clustering model. Clustering is an unsupervised learning problem where we intend to find clusters of points in our dataset that share some common characteristics.  </p>
<h1 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h1><p>$\mathcal{X}$ input space ($p$ dimensions)<br>$\mathbf{x}$ input variable $\mathbf{x} \in \mathcal{X}$<br>$n$ train sample size<br>$\mathbf{x}_i$ training input, $i= 1, \dots, n$<br>$d(\mathbf{x}_i,\mathbf{x}_j)$ distance between $\mathbf{x}_i,\mathbf{x}_j$<br>$K$ number of clusters<br>$\mathcal{C}(\mathbf{x}_i) = k$ encoder that assigns $\mathbf{x}_i$ to cluster $k$, $k\in \lbrace 1,\dots K\rbrace $<br>$n_k$ sample size for cluster $k$</p>
<p>The goal of clustering is to partition observations into groups (clusters) so that similar observations should be assigned to same cluster. Assume we expect to have in total $K$ clusters and each one is labeled by an integer $k\in \lbrace 1,\dots K\rbrace$</p>
<ul>
<li>Combinatorial algorithm </li>
</ul>
<h1 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h1><p>Combinatorial algorithm assgins each observation to <strong>one and only one group or cluster </strong>without regard to a underlying probability model. This assignment can be characterized by a encoder $\mathcal{C}(\mathbf{x}_i) = k$. Combinatorial algorithm aims to find the particular encoder such that </p>
<script type="math/tex; mode=display">\min \frac{1}{2}\sum_{k=1}^K \sum_{\mathcal{C}(\mathbf{x}_i) = k} \sum_{\mathcal{C}(\mathbf{x}_j) = k} d(\mathbf{x}_i,\mathbf{x}_j)</script><p>This criterion characterize the extent to which observations assigned to the same cluster tend to be close to another one. It can also be interpreted as “within cluster” distance if we have the decomposition of total pairwise distance as follow</p>
<script type="math/tex; mode=display">\begin{aligned}
T=& \frac{1}{2} \sum_{k=1}^K \sum_{i=1}^n \sum_{j=1}^n d(\mathbf{x}_i,\mathbf{x}_j) \\
 =& \frac{1}{2} \sum_{k=1}^K \sum_{\mathcal{C}(\mathbf{x}_i) = k} (\sum_{\mathcal{C}(\mathbf{x}_j) = k} d(\mathbf{x}_i,\mathbf{x}_j) + \sum_{\mathcal{C}(\mathbf{x}_j) \ne k} d(\mathbf{x}_i,\mathbf{x}_j))\\
 =& W(\mathcal{C}) + B(\mathcal{C})
\end{aligned}</script><p>where $W(\mathcal{C})$ is the loss function introduced above called “within cluster” distance and $B(\mathcal{C})$ represents “between cluster” distance. Since $T$ is a constant value given data, minimizing $W(\mathcal{C})$ is equivalent to maximizing $B(\mathcal{C})$</p>
<p>K-means algorithm is one of the most popular iterative descent clustering method and it defines distance function as squared Euclidean distance.</p>
<script type="math/tex; mode=display">d(\mathbf{x}_i,\mathbf{x}_j)=\sum_{q=1}^p(x_{iq}-x_{jq})^2 = ||\mathbf{x}_i-\mathbf{x}_j||^2</script><p>Then for each cluster, “within cluster” distance can be simplified</p>
<script type="math/tex; mode=display">\begin{aligned}
&\frac{1}{2}\sum_{\mathcal{C}(\mathbf{x}_i) = k}\sum_{\mathcal{C}(\mathbf{x}_j) = k} ||\mathbf{x}_i-\mathbf{x}_j||^2\\ 
=&\frac{1}{2}\sum_{\mathcal{C}(\mathbf{x}_i) = k}\sum_{\mathcal{C}(\mathbf{x}_j) = k} ||\mathbf{x}_i- \bar{\mathbf{x}}_k - (\mathbf{x}_j -  \bar{\mathbf{x}}_k) ||^2\\
=&\frac{1}{2}\sum_{\mathcal{C}(\mathbf{x}_i) = k}\sum_{\mathcal{C}(\mathbf{x}_j) = k} ||\mathbf{x}_i- \bar{\mathbf{x}}_k||^2  + ||(\mathbf{x}_j -  \bar{\mathbf{x}}_k) ||^2 -2(\mathbf{x}_i- \bar{\mathbf{x}}_k)^T(\mathbf{x}_j -  \bar{\mathbf{x}}_k)\\
=&\frac{1}{2}\sum_{\mathcal{C}(\mathbf{x}_i) = k} n_k ||\mathbf{x}_i- \bar{\mathbf{x}}_k||^2 +\frac{1}{2}n_k \sum_{\mathcal{C}(\mathbf{x}_j) = k}  ||\mathbf{x}_i- \bar{\mathbf{x}}_k||^2\\& + \sum_{\mathcal{C}(\mathbf{x}_i) = k}(\mathbf{x}_i- \bar{\mathbf{x}}_k)^T \sum_{\mathcal{C}(\mathbf{x}_j) = k}(\mathbf{x}_j - \bar{\mathbf{x}}_k) \\
=& n_k \sum_{\mathcal{C}(\mathbf{x}_j) = k}  ||\mathbf{x}_i- \bar{\mathbf{x}}_k||^2 
\end{aligned}</script><p>where $n_k$ is the sample size of cluster $k$ and $\bar{\mathbf{x}}_k$ is the mean vector of cluster $k$. The loss function can be written as</p>
<script type="math/tex; mode=display">W(\mathcal{C})=\sum_{k=1}^K n_k \sum_{\mathcal{C}(\mathbf{x}_j) = k}  ||\mathbf{x}_i- \bar{\mathbf{x}}_k||^2</script><p>However, for either original loss function or this one using Euclidean distance, it is time consuming with respect to sample size and number of clusters if we enumerate all possible clustering combination.</p>
<script type="math/tex; mode=display">S(n,K)=\frac{1}{K!}\sum_{k=1}^{K}(-1)^{K-k}\dbinom{K}{k}k^n</script><p>Hence, most clustering models use an iterative greedy descent strategy to find a suboptimal partition. We first initialize a partition and at each iterative step the partition are modified in a way such that loss function (or any criterion) is improved from previous value. </p>
<h2 id="training-algorithm"><a href="#training-algorithm" class="headerlink" title="training algorithm"></a>training algorithm</h2><ol>
<li>Initialize a cluster assignment $\mathcal{C^0}$</li>
<li>For a given assignment $\mathcal{C^t}$, calculate cluster means $\mu_k^t = \bar{\mathbf{x}}_k$ (which minimized the cluster variance)</li>
<li>Given cluster means $\mu_k^t$, update the assignment $\mathcal{C^{t+1}}$ that assign each observation to the closest cluster mean<script type="math/tex; mode=display">\mathcal{C}^{t+1}(\mathbf{x})=\arg \min_{k}||d(\mathbf{x},\mu_k^t)||</script></li>
<li>if $\mathcal{C^t}=\mathcal{C}^{t+1}$: return $\mathcal{C}^{t+1}$<br>else: t=t+1, go back to step 2.</li>
</ol>
<h1 id="Gaussian-Mixture-Model-GMM"><a href="#Gaussian-Mixture-Model-GMM" class="headerlink" title="Gaussian Mixture Model (GMM)"></a>Gaussian Mixture Model (GMM)</h1><p>Gaussian mixture models are a probabilistic model for representing normally distributed subpopulations within an overall population. GMMs have been used for <strong>feature extraction from speech data</strong>, and have also been used extensively in <strong>object tracking</strong> of multiple objects, where the number of mixture components and their means predict object locations at each frame in a video sequence.<a href="https://brilliant.org/wiki/gaussian-mixture-model/" target="_blank" rel="noopener">GMM</a></p>
<h2 id="Gaussian-distribution"><a href="#Gaussian-distribution" class="headerlink" title="Gaussian distribution"></a>Gaussian distribution</h2><p>Recall that a (Multi-dimensional) Gaussian distribution is determined by two parameters: mean vector $\mu$ and covariance matrix $\Sigma$. The density function $\mathcal{N}(\mathbf{x}|\mu,\Sigma)$ is</p>
<script type="math/tex; mode=display">\mathcal{N}(\mathbf{x}|\mu,\Sigma)
=\frac{1}{\sqrt{2\pi|\Sigma|}}
\exp(-\frac{1}{2}(\mathbf{x}-\mu)^T\Sigma^{-1}(\mathbf{x}-\mu))</script><p>We can fit a single Gaussian distribution to a dataset $\mathbf{D}=\lbrace\mathbf{x}_i \rbrace$ by maximizing the likelihood (if no prior) and get the MLE estimator of $\mu$ and $\Sigma$.</p>
<script type="math/tex; mode=display">\begin{aligned}
L(\mu,\Sigma|\mathbf{D})=&\prod_{i=1}^n \mathcal{N}(\mathbf{x}|\mu,\Sigma)\\
=& (2\pi|\Sigma|)^{-\frac{n}{2}} \exp (\sum_{i=1}^n -\frac{1}{2}(\mathbf{x}_i-\mu)^T\Sigma^{-1}(\mathbf{x}_i-\mu) )
\end{aligned}</script><p>We know that the optimal parameter estimate is </p>
<script type="math/tex; mode=display">\hat{\mu}= \bar{\mathbf{x}}_i</script><script type="math/tex; mode=display">\hat{\Sigma}= \frac{1}{n}\sum_{i=1}^n (\mathbf{x}_i - \hat{\mu})(\mathbf{x}_i - \hat{\mu})^T</script><h2 id="Gaussian-Mixture"><a href="#Gaussian-Mixture" class="headerlink" title="Gaussian Mixture"></a>Gaussian Mixture</h2><p>In clustering scenario, we have data clustered with patterns and it is absolutely bad idea to fit our data in one Gaussian Distribution. Instead, we assume we have several Gaussian Distributions with different parameters and our data are sampled from a distribution mixed by them. </p>
<p>The mixture is imposed on density function</p>
<script type="math/tex; mode=display">p(x|\mu_{\cdot},\Sigma_{\cdot},\alpha_{\cdot})=\sum_{k=1}^K\alpha_k\mathcal{N}(\mathbf{x}|\mu_k,\Sigma_k), \ \sum_{k=1}^K\alpha_k=1</script><p>We can still fit a Gaussian Mixture distribution to a dataset $\mathbf{D}=\lbrace\mathbf{x}_i \rbrace$ by maximizing the likelihood</p>
<script type="math/tex; mode=display">\begin{aligned}
L(\mu_k,\Sigma_k,\alpha_k|\mathbf{D})=&\prod_{i=1}^n p(\mathbf{x}|\mu_{\cdot},\Sigma_{\cdot},\alpha_{\cdot})\\
=& 
\end{aligned}</script><h1 id="EM"><a href="#EM" class="headerlink" title="EM"></a>EM</h1><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" rel="noopener">The Elements of Statistical Learning</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2019/12/25/Hyperparameter/" rel="next" title="Hyperparameter tuning">
                  <i class="fa fa-chevron-left"></i> Hyperparameter tuning
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/01/07/python-increment/" rel="prev" title="Behaviour of increment and decrement operators in Python">
                  Behaviour of increment and decrement operators in Python <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Notation"><span class="nav-number">1.</span> <span class="nav-text">Notation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#K-means"><span class="nav-number">2.</span> <span class="nav-text">K-means</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#training-algorithm"><span class="nav-number">2.1.</span> <span class="nav-text">training algorithm</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Gaussian-Mixture-Model-GMM"><span class="nav-number">3.</span> <span class="nav-text">Gaussian Mixture Model (GMM)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-distribution"><span class="nav-number">3.1.</span> <span class="nav-text">Gaussian distribution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-Mixture"><span class="nav-number">3.2.</span> <span class="nav-text">Gaussian Mixture</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#EM"><span class="nav-number">4.</span> <span class="nav-text">EM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Jiaxin Zhang"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jiaxin Zhang</p>
  <div class="site-description" itemprop="description">4+ years experience in programming. Familiar with python, SQL server, R, and Git. Highly motivated and humble to learn new things and learn fast with practice. Enjoy teamwork with strong sense of responsibility and communication skills, but also able to work individually with high efficiency, strong self-discipline and problem solving ability.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiaxin Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
