<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Jiaxin Zhang" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="12345import timeimport stringimport requestsimport reimport pandas as pd 12from selenium import webdriverdriver = webdriver.Firefox() Scraping all work urls from main personal page12345678910URL = &quot;ht">
<meta name="keywords" content="Web scraping">
<meta property="og:type" content="article">
<meta property="og:title" content="Scraping Changba data with python + selenium">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;02&#x2F;02&#x2F;changba&#x2F;index.html">
<meta property="og:site_name" content="Jiaxin Zhang">
<meta property="og:description" content="12345import timeimport stringimport requestsimport reimport pandas as pd 12from selenium import webdriverdriver = webdriver.Firefox() Scraping all work urls from main personal page12345678910URL = &quot;ht">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2020-02-03T22:22:15.126Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/02/02/changba/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Scraping Changba data with python + selenium | Jiaxin Zhang</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiaxin Zhang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">MSc in Statistical Machine Learning @ UofA</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/JasonZhang0619" class="github-corner" title="GitHub" aria-label="GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/02/changba/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Jiaxin Zhang">
      <meta itemprop="description" content="4+ years experience in programming. Familiar with python, SQL server, R, and Git. Highly motivated and humble to learn new things and learn fast with practice. Enjoy teamwork with strong sense of responsibility and communication skills, but also able to work individually with high efficiency, strong self-discipline and problem solving ability.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaxin Zhang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Scraping Changba data with python + selenium
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-02 19:34:18" itemprop="dateCreated datePublished" datetime="2020-02-02T19:34:18-07:00">2020-02-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-03 15:22:15" itemprop="dateModified" datetime="2020-02-03T15:22:15-07:00">2020-02-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br></pre></td></tr></table></figure>
<h1 id="Scraping-all-work-urls-from-main-personal-page"><a href="#Scraping-all-work-urls-from-main-personal-page" class="headerlink" title="Scraping all work urls from main personal page"></a>Scraping all work urls from main personal page</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">URL = <span class="string">"http://changba.com/u/26936044"</span></span><br><span class="line">driver.get(URL)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>: </span><br><span class="line">        driver.find_element_by_id(<span class="string">"loadWork"</span>).click()</span><br><span class="line">    <span class="keyword">except</span>: </span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#the main page only shows your most recent works which is only part of the whole list</span></span><br><span class="line"><span class="comment">#we need to keep clicking "加載更多" (load more) until we no more available</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if we only want the name list:</span></span><br><span class="line">work_list=driver.find_element_by_id(<span class="string">'work_list'</span>)</span><br><span class="line">len(work_list.text.split(<span class="string">'\n'</span>))</span><br></pre></td></tr></table></figure>
<pre><code>837
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get the list of name and corresponding url</span></span><br><span class="line">WorkUrl_list=[]</span><br><span class="line">works=driver.find_elements_by_class_name(<span class="string">'userPage-work-li'</span>) <span class="comment"># all work nodes belong to this class</span></span><br><span class="line"><span class="comment">#you can also use clearfix which actually works better since the last one does not belongs to this class</span></span><br><span class="line"><span class="keyword">for</span> work <span class="keyword">in</span> works:</span><br><span class="line">    <span class="keyword">try</span>: </span><br><span class="line">        child=work.find_element_by_xpath(<span class="string">".//*"</span>)</span><br><span class="line">	<span class="comment">#By this step i can find the only child (attribute node) with attributes &lt;a href=...&gt;&lt;/a&gt;</span></span><br><span class="line">    <span class="keyword">except</span>: </span><br><span class="line">        <span class="keyword">break</span> <span class="comment">#the last one is blank with no child</span></span><br><span class="line">    name=string.capwords(child.text.split(<span class="string">'【'</span>)[<span class="number">0</span>].lower())<span class="comment">#Name Format</span></span><br><span class="line">    url=child.get_attribute(<span class="string">'href'</span>)</span><br><span class="line">    WorkUrl_list.append((name,url)) <span class="comment"># save a list of tuples [(work name, url)]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(WorkUrl_list)</span><br></pre></td></tr></table></figure>
<pre><code>837
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#for work in works:</span></span><br><span class="line"><span class="comment">#    url=driver.find_element_by_link_text(work.text).get_attribute('href')</span></span><br><span class="line"><span class="comment">#    WorkUrl_list.append((work.text,url))</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_pages = pd.DataFrame(WorkUrl_list, columns = [<span class="string">'name'</span>, <span class="string">'Page'</span>])</span><br></pre></td></tr></table></figure>
<h1 id="Scraping-a-page-for-single-work"><a href="#Scraping-a-page-for-single-work" class="headerlink" title="Scraping a page for single work"></a>Scraping a page for single work</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_pages.loc[<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<pre><code>name                                           Nasa
Page    http://changba.com/s/GZr_J5_BvVpGx_odmAqtBQ
Name: 3, dtype: object
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#scrap some info about this work</span></span><br><span class="line">URL = pd_pages.loc[<span class="number">3</span>].Page <span class="comment"># get url</span></span><br><span class="line">driver.get(URL) <span class="comment"># get page </span></span><br><span class="line">audience=driver.find_element_by_class_name(<span class="string">'audience'</span>).text <span class="comment"># get information in audience node</span></span><br><span class="line">comment=driver.find_element_by_class_name(<span class="string">'comment'</span>).text</span><br><span class="line">presents=driver.find_element_by_class_name(<span class="string">'presents'</span>).text</span><br><span class="line">share=driver.find_element_by_class_name(<span class="string">'share'</span>).text</span><br></pre></td></tr></table></figure>
<p>Bad new is there is no time info available on the website (unlike phone). The only way we can estimate the submitting time is to use the earliest comment posting time. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#estimate submitting time</span></span><br><span class="line">times=driver.find_elements_by_class_name(<span class="string">'post-time'</span>) <span class="comment">#get post-time of comments</span></span><br><span class="line"><span class="keyword">if</span> len(times) &gt;<span class="number">0</span>: <span class="comment"># if there is comments</span></span><br><span class="line">    time=pd.Timestamp(times[<span class="number">-1</span>].text) <span class="comment"># take the earliest time</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#locate and scrap the url of this work</span></span><br><span class="line">html=str(requests.get(URL).content)</span><br><span class="line">start, end =re.search(<span class="string">r'http://upscuw.changba.com/\d*\.mp3'</span>,html).span() <span class="comment"># find mp3 file url in raw html</span></span><br><span class="line">song_url=html[start:end]</span><br></pre></td></tr></table></figure>
<h1 id="For-all-pages"><a href="#For-all-pages" class="headerlink" title="For all pages"></a>For all pages</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException</span><br><span class="line"><span class="comment">#it happens when the page is forbidden</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd_urls=pd.DataFrame(<span class="literal">None</span>,</span><br><span class="line">                     columns = [<span class="string">'audience'</span>, <span class="string">'comment'</span>,<span class="string">'presents'</span>,<span class="string">'share'</span>,<span class="string">'url'</span>,<span class="string">'Time'</span>],</span><br><span class="line">                     index=pd_pages.index)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pd_urls.index:</span><br><span class="line">    URL = pd_pages.loc[i].Page</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        driver.get(URL)</span><br><span class="line">        pd_urls.audience[i]=driver.find_element_by_class_name(<span class="string">'audience'</span>).text</span><br><span class="line">        pd_urls.comment[i]=driver.find_element_by_class_name(<span class="string">'comment'</span>).text</span><br><span class="line">        pd_urls.presents[i]=driver.find_element_by_class_name(<span class="string">'presents'</span>).text</span><br><span class="line">        pd_urls.share[i]=driver.find_element_by_class_name(<span class="string">'share'</span>).text</span><br><span class="line">        </span><br><span class="line">        times=driver.find_elements_by_class_name(<span class="string">'post-time'</span>) <span class="comment">#get post-time of comments</span></span><br><span class="line">        <span class="keyword">if</span> len(times) &gt;<span class="number">0</span>: <span class="comment"># if there is comments</span></span><br><span class="line">            pd_urls.Time[i]=pd.Timestamp(times[<span class="number">-1</span>].text) <span class="comment"># take the earliest time</span></span><br><span class="line">        </span><br><span class="line">        html=str(requests.get(URL).content)</span><br><span class="line">        start, end =re.search(<span class="string">r'a="https*://.*\.changba\.com.*/\d*\.mp3'</span>,html).span()</span><br><span class="line">        pd_urls.url[i]=html[start+<span class="number">3</span>:end] <span class="comment"># updated from previous one to be more robost.</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> NoSuchElementException: <span class="comment"># the work is not permited to access due to sensitive words in name</span></span><br><span class="line">        print(<span class="string">'NoSuchElementException for index '</span>,i)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">except</span> AttributeError: <span class="comment"># no .mp3 file found in html (if there is a mv)</span></span><br><span class="line">        print(<span class="string">'AttributeError for index '</span>,i)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt: <span class="comment"># control to stop </span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    time.sleep(<span class="number">2</span>) <span class="comment"># avoid frequent request (previous steps are slow tho)</span></span><br></pre></td></tr></table></figure>
<pre><code>AttributeError for index  157
NoSuchElementException for index  171
NoSuchElementException for index  179
NoSuchElementException for index  233
NoSuchElementException for index  394
AttributeError for index  399
NoSuchElementException for index  469
NoSuchElementException for index  478
NoSuchElementException for index  484
AttributeError for index  540
AttributeError for index  541
NoSuchElementException for index  557
NoSuchElementException for index  736
NoSuchElementException for index  790
AttributeError for index  803
AttributeError for index  805
AttributeError for index  808
AttributeError for index  813
AttributeError for index  821
AttributeError for index  822
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.close()</span><br><span class="line">pd_urls.to_csv(<span class="string">'changba_urls.csv'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd_merge=pd_pages.join(pd_urls)</span><br><span class="line">pd_merge</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>Page</th>
      <th>audience</th>
      <th>comment</th>
      <th>presents</th>
      <th>share</th>
      <th>url</th>
      <th>Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>忘我</td>
      <td>http://changba.com/s/EXb4wphbN-GY464jDRV_KA</td>
      <td>64</td>
      <td>4</td>
      <td>8</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/9...</td>
      <td>2019-12-29 00:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Real Friends</td>
      <td>http://changba.com/s/FBZMCWgrLY3sO7sUEFbgSg</td>
      <td>32</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>http://ksapuw.changba.com/userdata/userwork/81...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When I Was Your Man</td>
      <td>http://changba.com/s/GZr_J5_BvVr4a-ftEiASmw</td>
      <td>29</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>http://upscuw.changba.com/1208653739.mp3</td>
      <td>2019-12-29 00:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Nasa</td>
      <td>http://changba.com/s/GZr_J5_BvVpGx_odmAqtBQ</td>
      <td>25</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>http://upscuw.changba.com/1208653711.mp3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Scars To Your</td>
      <td>http://changba.com/s/oTPTKN_3qXjKpIfapWDAAA</td>
      <td>16</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://qiniuuwmp3.changba.com/1208653567.mp3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>832</th>
      <td>恒星流星</td>
      <td>http://changba.com/s/lxnKkg0S0RVrwOn6rjxZOg</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/8...</td>
      <td>2013-08-05 00:00:00</td>
    </tr>
    <tr>
      <th>833</th>
      <td>也许明天</td>
      <td>http://changba.com/s/z1FbhFD6pZ669cvjWIcqfA</td>
      <td>106</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/8...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>834</th>
      <td>剪爱</td>
      <td>http://changba.com/s/TIO4hN908E8Wndka1ntQpQ</td>
      <td>26</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/7...</td>
      <td>2013-08-01 00:00:00</td>
    </tr>
    <tr>
      <th>835</th>
      <td>空白格</td>
      <td>http://changba.com/s/co-YKmeP2LT5THi79AR9gQ</td>
      <td>72</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/5...</td>
      <td>2013-08-15 00:00:00</td>
    </tr>
    <tr>
      <th>836</th>
      <td>Listen</td>
      <td>http://changba.com/s/BCpW1QzqtJp1bFGVkMadXw</td>
      <td>63</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/4...</td>
      <td>2013-08-01 00:00:00</td>
    </tr>
  </tbody>
</table>
<p>837 rows × 8 columns</p>
</div>



<h2 id="One-interesting-question"><a href="#One-interesting-question" class="headerlink" title="One interesting question"></a>One interesting question</h2><p>Recall that we estimate the submitting time by earliest comment time, some work has <strong>no comment</strong> and some work are firstly commented <strong>later than submitted</strong>. Hence,the time stamps are collected with some <strong>missing time</strong> and some <strong>delayed time</strong> and we want to correct them such that our time stamps should be consistent in <strong>non-increasing order</strong>. How to correct this time series?</p>
<p>Denote the timesatamps as $t_i$ and our estimate as $\hat{t}_i$, what we are sure about is:</p>
<ul>
<li>$t_{i+1}\ge t_i$</li>
<li>$\hat{t}_i\ge t_i$   if $\hat{t}_i$ is not missing</li>
<li>we assume that most timestamp estimates including the first and the last one are correct.</li>
</ul>
<p>How can we check if a timestamp series is non-increasing?</p>
<p>A: it is non-increasing everywhere. any adjacent pais is non-increasing.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_non_increasing</span><span class="params">(times)</span>:</span></span><br><span class="line">    increase=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(times)<span class="number">-1</span>):</span><br><span class="line">        now=i</span><br><span class="line">        before=i+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> times[now]&lt;times[before]: <span class="comment"># there is a increase.</span></span><br><span class="line">            increase+=<span class="number">1</span> <span class="comment"># you can also stop and return something here</span></span><br><span class="line">    <span class="keyword">return</span> increase</span><br></pre></td></tr></table></figure>
<p>There are two extreme ways of correction:</p>
<ul>
<li>get the upper bound of corrected time</li>
</ul>
<p>for each correction, let it be as large as possible，向前看齊</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pd_merge[<span class="string">'CorrectedTime_U'</span>]=<span class="literal">None</span></span><br><span class="line">earliest_time=pd_merge.Time[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pd_merge.index:</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">not</span> pd.isna(pd_merge.Time[i]) <span class="keyword">and</span> pd_merge.Time[i] &lt;= earliest_time):</span><br><span class="line">        earliest_time = pd_merge.Time[i]</span><br><span class="line">    pd_merge.CorrectedTime_U[i] = earliest_time</span><br></pre></td></tr></table></figure>
<ul>
<li>get the lower bound of corrected time</li>
</ul>
<p>for each correction, let it be as small as possible, 向後看齊</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pd_merge[<span class="string">'CorrectedTime_L'</span>]=<span class="literal">None</span></span><br><span class="line">pd_merge[<span class="string">'fault'</span>]=<span class="literal">False</span></span><br><span class="line">earliest_time=pd_merge.Time[<span class="number">0</span>]<span class="comment"># the latest time observed so far</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pd_merge.index:</span><br><span class="line">    <span class="keyword">if</span> pd.isna(pd_merge.Time[i]) <span class="keyword">or</span> pd_merge.Time[i] &gt; earliest_time:</span><br><span class="line">        pd_merge.fault[i]=<span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        earliest_time = pd_merge.Time[i]</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anoconda\envs\Python\lib\site-packages\ipykernel_launcher.py:6: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">latest_time=pd_merge.Time[<span class="number">836</span>]<span class="comment"># the latest time observed so far</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">836</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pd_merge.fault[i]:</span><br><span class="line">        latest_time = pd_merge.Time[i]</span><br><span class="line">    pd_merge.CorrectedTime_L[i]=latest_time</span><br></pre></td></tr></table></figure>
<pre><code>D:\Anoconda\envs\Python\lib\site-packages\ipykernel_launcher.py:5: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  &quot;&quot;&quot;
</code></pre><p>check if there is still faults</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">check_non_increasing(pd_merge.CorrectedTime_L)</span><br></pre></td></tr></table></figure>
<pre><code>0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">check_non_increasing(pd_merge.CorrectedTime_U)</span><br></pre></td></tr></table></figure>
<pre><code>0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_merge</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>Page</th>
      <th>audience</th>
      <th>comment</th>
      <th>presents</th>
      <th>share</th>
      <th>url</th>
      <th>Time</th>
      <th>CorrectedTime_U</th>
      <th>CorrectedTime_L</th>
      <th>fault</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>忘我</td>
      <td>http://changba.com/s/EXb4wphbN-GY464jDRV_KA</td>
      <td>64</td>
      <td>4</td>
      <td>8</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/9...</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-29 00:00:00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Real Friends</td>
      <td>http://changba.com/s/FBZMCWgrLY3sO7sUEFbgSg</td>
      <td>32</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>http://ksapuw.changba.com/userdata/userwork/81...</td>
      <td>NaN</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-29 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When I Was Your Man</td>
      <td>http://changba.com/s/GZr_J5_BvVr4a-ftEiASmw</td>
      <td>29</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>http://upscuw.changba.com/1208653739.mp3</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-29 00:00:00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Nasa</td>
      <td>http://changba.com/s/GZr_J5_BvVpGx_odmAqtBQ</td>
      <td>25</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>http://upscuw.changba.com/1208653711.mp3</td>
      <td>NaN</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-28 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Scars To Your</td>
      <td>http://changba.com/s/oTPTKN_3qXjKpIfapWDAAA</td>
      <td>16</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://qiniuuwmp3.changba.com/1208653567.mp3</td>
      <td>NaN</td>
      <td>2019-12-29 00:00:00</td>
      <td>2019-12-28 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>832</th>
      <td>恒星流星</td>
      <td>http://changba.com/s/lxnKkg0S0RVrwOn6rjxZOg</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/8...</td>
      <td>2013-08-05 00:00:00</td>
      <td>2013-08-02 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>833</th>
      <td>也许明天</td>
      <td>http://changba.com/s/z1FbhFD6pZ669cvjWIcqfA</td>
      <td>106</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/8...</td>
      <td>NaN</td>
      <td>2013-08-02 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>834</th>
      <td>剪爱</td>
      <td>http://changba.com/s/TIO4hN908E8Wndka1ntQpQ</td>
      <td>26</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/7...</td>
      <td>2013-08-01 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>False</td>
    </tr>
    <tr>
      <th>835</th>
      <td>空白格</td>
      <td>http://changba.com/s/co-YKmeP2LT5THi79AR9gQ</td>
      <td>72</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/5...</td>
      <td>2013-08-15 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>True</td>
    </tr>
    <tr>
      <th>836</th>
      <td>Listen</td>
      <td>http://changba.com/s/BCpW1QzqtJp1bFGVkMadXw</td>
      <td>63</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>http://upuwmp3.changba.com/userdata/userwork/4...</td>
      <td>2013-08-01 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>2013-08-01 00:00:00</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>837 rows × 11 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd_merge.to_csv(<span class="string">'changba.csv'</span>,encoding=<span class="string">"utf-8-sig"</span>)</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Web-scraping/" rel="tag"># Web scraping</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/01/13/SVM/" rel="next" title="Lagrange Duality and SVM">
                  <i class="fa fa-chevron-left"></i> Lagrange Duality and SVM
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Scraping-all-work-urls-from-main-personal-page"><span class="nav-number">1.</span> <span class="nav-text">Scraping all work urls from main personal page</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scraping-a-page-for-single-work"><span class="nav-number">2.</span> <span class="nav-text">Scraping a page for single work</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#For-all-pages"><span class="nav-number">3.</span> <span class="nav-text">For all pages</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#One-interesting-question"><span class="nav-number">3.1.</span> <span class="nav-text">One interesting question</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Jiaxin Zhang"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jiaxin Zhang</p>
  <div class="site-description" itemprop="description">4+ years experience in programming. Familiar with python, SQL server, R, and Git. Highly motivated and humble to learn new things and learn fast with practice. Enjoy teamwork with strong sense of responsibility and communication skills, but also able to work individually with high efficiency, strong self-discipline and problem solving ability.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiaxin Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
