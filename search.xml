<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Gini Index vs Entropy</title>
    <url>/2019/11/28/Entropy/</url>
    <content><![CDATA[<p><strong>Gini Index</strong> and <strong>Entropy</strong> are two types of measure of <strong>impurity</strong> of distribution which is used in information-gain rules in decision tree. </p>
<h1 id="Gini-Index"><a href="#Gini-Index" class="headerlink" title="Gini Index"></a>Gini Index</h1><p>The formula for Gini index is direct. Given (k)</p>
<p>$k$</p>
<script type="math/tex; mode=display">k</script>]]></content>
  </entry>
  <entry>
    <title>SSC</title>
    <url>/2019/11/03/SSC/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">"C:\\Users\\jason\\Desktop\\SSC2019CaseStudy"</span>)</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Explore-the-cell-images"><a href="#Explore-the-cell-images" class="headerlink" title="Explore the cell images"></a>Explore the cell images</h1><h2 id="load-train-dataset"><a href="#load-train-dataset" class="headerlink" title="load train dataset"></a>load train dataset</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df=pd.read_csv(<span class="string">'train_label.csv'</span>,index_col=<span class="string">'image_name'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>image_name</th>
      <th>count</th>
      <th>blur</th>
      <th>stain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A01_C1_F1_s01_w2.TIF</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>A01_C1_F1_s02_w1.TIF</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>A01_C1_F1_s02_w2.TIF</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>A01_C1_F1_s03_w2.TIF</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>A01_C1_F1_s04_w2.TIF</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n=<span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    plt.subplot(<span class="number">1</span>,n,i+<span class="number">1</span>)</span><br><span class="line">    img_name=rd.choice(df.index)</span><br><span class="line">    im = Image.open(<span class="string">'train/'</span>+img_name)</span><br><span class="line">    im=np.array(im)</span><br><span class="line">    plt.imshow(im,cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(img_name)</span><br><span class="line">    plt.axis(<span class="string">'off'</span>)</span><br></pre></td></tr></table></figure>
<img src="/2019/11/03/SSC/output_3_0.png" class="" title="This is an image">
<h2 id="compare-img-with-different-cell-count"><a href="#compare-img-with-different-cell-count" class="headerlink" title="compare img with different cell count"></a>compare img with different cell count</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_name=[<span class="string">'A01_C1_F1_s13_w1.TIF'</span>,</span><br><span class="line">   <span class="string">'A02_C5_F1_s09_w1.TIF'</span>,</span><br><span class="line">    <span class="string">'A16_C66_F1_s04_w1.TIF'</span>]</span><br><span class="line">n=len(img_name)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    im = Image.open(<span class="string">'train/'</span>+img_name[i])</span><br><span class="line">    im=np.array(im)</span><br><span class="line">    plt.subplot(n,<span class="number">2</span>,<span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(im,cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(<span class="string">'count = '</span>+ str(df.loc[img_name[i],<span class="string">'count'</span>]))</span><br><span class="line">    plt.axis(<span class="string">'off'</span>)</span><br><span class="line">    plt.subplot(n,<span class="number">2</span>,<span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">    plt.hist(im.reshape(<span class="number">-1</span>,<span class="number">1</span>),bins=range(<span class="number">0</span>,<span class="number">256</span>,<span class="number">1</span>))</span><br><span class="line">    plt.yscale(<span class="string">'log'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'gray scale'</span>)</span><br></pre></td></tr></table></figure>
<img src="/2019/11/03/SSC/output_5_0.png" class="" title="This is an image">
<h2 id="compare-img-with-different-level-of-F-and-w"><a href="#compare-img-with-different-level-of-F-and-w" class="headerlink" title="compare img with different level of F and w"></a>compare img with different level of F and w</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_name = df.filter(like=<span class="string">'C14'</span>,axis=<span class="number">0</span>).filter(like=<span class="string">'s11'</span>,axis=<span class="number">0</span>).index</span><br><span class="line">n=len(img_name)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    im = Image.open(<span class="string">'train/'</span>+img_name[i])</span><br><span class="line">    im=np.array(im)</span><br><span class="line">    plt.subplot(n,<span class="number">2</span>,<span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(im,cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(<span class="string">'count = '</span>+ str(df.loc[img_name[i],<span class="string">'count'</span>]))</span><br><span class="line">    plt.axis(<span class="string">'off'</span>)</span><br><span class="line">    plt.subplot(n,<span class="number">2</span>,<span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">    plt.hist(im.reshape(<span class="number">-1</span>,<span class="number">1</span>),bins=range(<span class="number">0</span>,<span class="number">256</span>,<span class="number">1</span>))</span><br><span class="line">    plt.yscale(<span class="string">'log'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'gray scale'</span>)</span><br></pre></td></tr></table></figure>
<img src="/2019/11/03/SSC/output_7_0.png" class="" title="This is an image">
<h1 id="Linear-regression-with-grey-scale"><a href="#Linear-regression-with-grey-scale" class="headerlink" title="Linear regression with grey scale"></a>Linear regression with grey scale</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> Regression <span class="keyword">import</span> PoolRegressor</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> shuffle</span><br></pre></td></tr></table></figure>
<h2 id="For-F1-w1-images"><a href="#For-F1-w1-images" class="headerlink" title="For F1 w1 images"></a>For F1 w1 images</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">F = <span class="string">'F1'</span></span><br><span class="line">w = <span class="string">'w1'</span></span><br><span class="line">X, df = utils.read_imgset(csv_path=<span class="string">'train_label.csv'</span>,train=<span class="literal">True</span>, F=F, w=w, hist = <span class="literal">True</span>)</span><br><span class="line">X, df = shuffle(X, df, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="cross-validation"><a href="#cross-validation" class="headerlink" title="cross validation"></a>cross validation</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kf = KFold(n_splits=<span class="number">10</span>)</span><br><span class="line">fit=PoolRegressor(pool= <span class="literal">False</span>)</span><br><span class="line">mse_train=[]</span><br><span class="line">mse_test=[]</span><br><span class="line">df[<span class="string">'pred'</span>]=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf.split(X):</span><br><span class="line">    ytrain= df[<span class="string">'count'</span>][train]</span><br><span class="line">    fit.train(X[train,], df[<span class="string">'count'</span>][train])</span><br><span class="line">    ypred=fit.predict(X[train,])</span><br><span class="line">    mse_train.append( mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][train]))</span><br><span class="line">    ypred=fit.predict(X[test,])</span><br><span class="line">    df[<span class="string">'pred'</span>][test]=ypred</span><br><span class="line">    mse_test.append(mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][test]))</span><br><span class="line">print(<span class="string">'train mse = '</span>,np.mean(mse_train),<span class="string">'+/-'</span>, np.std(mse_train))</span><br><span class="line">print(<span class="string">'test mse = '</span>,np.mean(mse_test),<span class="string">'+/-'</span>, np.std(mse_test))</span><br></pre></td></tr></table></figure>
<pre><code>train mse =  0.09604340485504105 +/- 0.006622262312150045
test mse =  2.389303273614496 +/- 0.33634267102092574
</code></pre><p>train mse is way smaller than test mse, <strong>overfitting alert</strong>!</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">residual = np.array(df[<span class="string">'count'</span>]) - np.array(df[<span class="string">'pred'</span>])</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">6</span>,<span class="number">2.5</span>))</span><br><span class="line">_ = ax.scatter(np.array(df[<span class="string">'count'</span>]),residual)</span><br><span class="line">plt.xlabel(<span class="string">'true count'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'residuals'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;residuals&#39;)
</code></pre><img src="/2019/11/03/SSC/output_15_1.png" class="" title="This is an image">
<p>The error increase when more cells in the image</p>
<h2 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_name=[<span class="string">'A01_C1_F1_s13_w1.TIF'</span>,</span><br><span class="line">   <span class="string">'A02_C5_F1_s09_w1.TIF'</span>,</span><br><span class="line">    <span class="string">'A16_C66_F1_s04_w1.TIF'</span>]</span><br><span class="line">n=len(img_name)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    im = Image.open(<span class="string">'train/'</span>+img_name[i])</span><br><span class="line">    im=np.array(im)</span><br><span class="line">    plt.subplot(n,<span class="number">3</span>,<span class="number">3</span>*i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(im,cmap=<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(<span class="string">'count = '</span>+ str(df.loc[img_name[i],<span class="string">'count'</span>]))</span><br><span class="line">    plt.axis(<span class="string">'off'</span>)</span><br><span class="line">    plt.subplot(n,<span class="number">3</span>,<span class="number">3</span>*i+<span class="number">2</span>)</span><br><span class="line">    plt.hist(im.reshape(<span class="number">-1</span>,<span class="number">1</span>),bins=range(<span class="number">0</span>,<span class="number">256</span>,<span class="number">1</span>))</span><br><span class="line">    plt.yscale(<span class="string">'log'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'gray scale'</span>)</span><br><span class="line">    plt.subplot(n,<span class="number">3</span>,<span class="number">3</span>*i+<span class="number">3</span>)</span><br><span class="line">    plt.hist(im.reshape(<span class="number">-1</span>,<span class="number">1</span>),bins=range(<span class="number">0</span>,<span class="number">256</span>,<span class="number">15</span>))</span><br><span class="line">    plt.yscale(<span class="string">'log'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'gray scale'</span>)</span><br></pre></td></tr></table></figure>
<img src="/2019/11/03/SSC/output_18_0.png" class="" title="This is an image">
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fit=PoolRegressor(window=<span class="number">15</span>,step=<span class="number">15</span>,pool= <span class="literal">True</span>)</span><br><span class="line">mse_train=[]</span><br><span class="line">mse_test=[]</span><br><span class="line">df[<span class="string">'pooling_pred'</span>]=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf.split(X):</span><br><span class="line">    ytrain= df[<span class="string">'count'</span>][train]</span><br><span class="line">    fit.train(X[train,], df[<span class="string">'count'</span>][train])</span><br><span class="line">    ypred=fit.predict(X[train,])</span><br><span class="line">    mse_train.append( mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][train]))</span><br><span class="line">    ypred=fit.predict(X[test,])</span><br><span class="line">    df[<span class="string">'pooling_pred'</span>][test]=ypred</span><br><span class="line">    mse_test.append(mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][test]))</span><br><span class="line">print(<span class="string">'train mse = '</span>,np.mean(mse_train),<span class="string">'+/-'</span>, np.std(mse_train))</span><br><span class="line">print(<span class="string">'test mse = '</span>,np.mean(mse_test),<span class="string">'+/-'</span>, np.std(mse_test))</span><br></pre></td></tr></table></figure>
<pre><code>train mse =  0.5545320752842191 +/- 0.01830920026615093
test mse =  0.6205896336762233 +/- 0.17798416968612663
</code></pre><p>Overfitting issue is solved by pooling (setting wider bins)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">residual = np.array(df[<span class="string">'count'</span>]) - np.array(df[<span class="string">'pooling_pred'</span>])</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">6</span>,<span class="number">2.5</span>))</span><br><span class="line">_ = ax.scatter(np.array(df[<span class="string">'count'</span>]),residual)</span><br><span class="line">plt.xlabel(<span class="string">'true count'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'residuals'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;residuals&#39;)
</code></pre><img src="/2019/11/03/SSC/output_21_1.png" class="" title="This is an image">
<p><strong>heteroscedasticity</strong> the residuals still get larger as the prediction moves from small to large</p>
<p>How to Fix</p>
<ul>
<li>The most frequently successful solution is to <strong>transform</strong> a variable.</li>
<li>Often heteroscedasticity indicates that a <strong>variable is missing</strong>.</li>
</ul>
<h3 id="log-trasforamtion-failed"><a href="#log-trasforamtion-failed" class="headerlink" title="log trasforamtion (failed)"></a>log trasforamtion (failed)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_log=np.log(X+<span class="number">1</span>)</span><br><span class="line">fit=PoolRegressor(window=<span class="number">15</span>,step=<span class="number">15</span>,pool= <span class="literal">True</span>)</span><br><span class="line">mse_train=[]</span><br><span class="line">mse_test=[]</span><br><span class="line">df[<span class="string">'log_pred'</span>]=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf.split(X):</span><br><span class="line">    ytrain= df[<span class="string">'count'</span>][train]</span><br><span class="line">    fit.train(X_log[train,], df[<span class="string">'count'</span>][train])</span><br><span class="line">    ypred=fit.predict(X_log[train,])</span><br><span class="line">    mse_train.append( mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][train]))</span><br><span class="line">    ypred=fit.predict(X_log[test,])</span><br><span class="line">    df[<span class="string">'log_pred'</span>][test]=ypred</span><br><span class="line">    mse_test.append(mean_squared_error(y_pred=ypred,y_true=df[<span class="string">'count'</span>][test]))</span><br><span class="line">print(<span class="string">'train mse = '</span>,np.mean(mse_train),<span class="string">'+/-'</span>, np.std(mse_train))</span><br><span class="line">print(<span class="string">'test mse = '</span>,np.mean(mse_test),<span class="string">'+/-'</span>, np.std(mse_test))</span><br></pre></td></tr></table></figure>
<pre><code>train mse =  137.2764500289679 +/- 6.5020079871442205
test mse =  196.17602353002354 +/- 132.57460287167424
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">residual = np.array(df[<span class="string">'count'</span>]) - np.array(df[<span class="string">'log_pred'</span>])</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">6</span>,<span class="number">2.5</span>))</span><br><span class="line">_ = ax.scatter(np.array(df[<span class="string">'count'</span>]),residual)</span><br><span class="line">plt.xlabel(<span class="string">'true count'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'residuals'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;residuals&#39;)
</code></pre><img src="/2019/11/03/SSC/output_25_1.png" class="" title="This is an image">
<p>Patterns like this indicate that a variable needs to be transformed you probably need to create a <strong>nonlinear</strong> model</p>
<h2 id="Topology-feature"><a href="#Topology-feature" class="headerlink" title="Topology feature"></a>Topology feature</h2><h2 id="overlapping-example"><a href="#overlapping-example" class="headerlink" title="overlapping example"></a>overlapping example</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>hello-world</title>
    <url>/2019/11/03/hello-world/</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
